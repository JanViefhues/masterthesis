{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773518ed-ff55-4ce7-8079-abdbbe225ec8",
   "metadata": {},
   "source": [
    "# Build model to estimate the best Hyperparameters for the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f25f4-30a8-4235-ab63-3dabc3e42a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Follow literature advice and use 10-fold cross validation to avoid for overfitting\n",
    "\n",
    "\n",
    "def calculate_hyperparameters(dataset, target, features):\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from pprint import pprint\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "    X=dataset[features] # Has to be an array]  # Features\n",
    "    y=dataset[target]  # Labels\n",
    "\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X, y)\n",
    "\n",
    "    print(rf_random.best_params_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74bf3b0-9223-4309-b8df-64e5d4bf6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335b961-079c-4b37-9656-fda7977586ed",
   "metadata": {},
   "source": [
    "# Run Hyperparameter Calculation for Flood as label (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0e5236f-4850-4fc6-8b00-a2d7effee03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "target_hyperparameter_calculation = 'IsFloodingPeriode' # Can be any kind of data type\n",
    "features_hyperparameter_calculation = ['CO2','abnormal_Co2_leakage','PM25', 'PM10', 'Temperature', 'Humidity', 'Pressure', 'Precipitation','mine_water_level', 'ground_water_level','RhineWaterLevel','Stream_water_level','Discharge'] # Has to be an array\n",
    "\n",
    "# Call hyperparameter model\n",
    "dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "\n",
    "calculate_hyperparameters(dataset, target_hyperparameter_calculation,features_hyperparameter_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e913a4aa-d871-494c-ad41-1f2c7b3be0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the defined hyperparameters and calculate the accuracy\n",
    "\n",
    "print(f'Train Accuracy - : {rf_random.score(X_train, y_train):.3f}')\n",
    "print(f'Test Accuracy - : {rf_random.score(X_test, y_test):.3f}')\n",
    "\n",
    "# The accuracy rates on both sets are euqal enough. We dont have overfitting issue here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ffbf52",
   "metadata": {},
   "source": [
    "### Hyperparameter Calculation for Flood only 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc74b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_hyperparameter_calculation = 'IsFloodingPeriode' # Can be any kind of data type\n",
    "eight_features_hyperparameter_calculation = ['mine_water_level','ground_water_level','Stream_water_level', 'RhineWaterLevel', 'Humidity','Temperature','Discharge','Pressure'] # Has to be an array\n",
    "\n",
    "dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "\n",
    "calculate_hyperparameters(dataset, target_hyperparameter_calculation,eight_features_hyperparameter_calculation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e141df77-1659-4bfd-86a1-ac7b2b5c57a4",
   "metadata": {},
   "source": [
    "# Run Hyperparameter Calculation for CO2 leakage as label (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728cfb89-295e-4d2c-ae7c-a992e9a0a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Data set\n",
    "\n",
    "# Set features\n",
    "target_hyperparameter_calculation_abnormalCO2 = 'abnormal_Co2_leakage' # Can be any kind of data type\n",
    "features_hyperparameter_calculation_abnormalCO2 = ['IsFloodingPeriode','PM25', 'PM10', 'Temperature', 'Humidity', 'Pressure', 'Precipitation','mine_water_level', 'ground_water_level','RhineWaterLevel','Stream_water_level','Discharge'] # Has to be an array\n",
    "\n",
    "# Call hyperparameter model\n",
    "#dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/hourly_dataset.before.flooding_with_precipitation_and_dummies.csv')\n",
    "calculate_hyperparameters(dataset, target_hyperparameter_calculation_abnormalCO2,features_hyperparameter_calculation_abnormalCO2)\n",
    "\n",
    "\n",
    "# Result\n",
    "#Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "# {'n_estimators': 1600, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6580c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# During Data set\n",
    "\n",
    "# Set features\n",
    "target_hyperparameter_calculation_abnormalCO2 = 'abnormal_Co2_leakage' # Can be any kind of data type\n",
    "features_hyperparameter_calculation_abnormalCO2 = ['IsFloodingPeriode','PM25', 'PM10', 'Temperature', 'Humidity', 'Pressure', 'Precipitation','mine_water_level', 'ground_water_level','RhineWaterLevel','Stream_water_level','Discharge'] # Has to be an array\n",
    "\n",
    "# Call hyperparameter model\n",
    "#dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/hourly_dataset.during.flooding_with_precipitation_and_dummies.csv')\n",
    "calculate_hyperparameters(dataset, target_hyperparameter_calculation_abnormalCO2,features_hyperparameter_calculation_abnormalCO2)\n",
    "\n",
    "\n",
    "# Result\n",
    "#Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "# best_parameters = {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71877b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Data set\n",
    "\n",
    "# Set features\n",
    "target_hyperparameter_calculation_abnormalCO2 = 'abnormal_Co2_leakage' # Can be any kind of data type\n",
    "features_hyperparameter_calculation_abnormalCO2 = ['IsFloodingPeriode','PM25', 'PM10', 'Temperature', 'Humidity', 'Pressure', 'Precipitation','mine_water_level', 'ground_water_level','RhineWaterLevel','Stream_water_level','Discharge'] # Has to be an array\n",
    "\n",
    "# Call hyperparameter model\n",
    "#dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/hourly_dataset.after.flooding_with_precipitation_and_dummies.csv')\n",
    "calculate_hyperparameters(dataset, target_hyperparameter_calculation_abnormalCO2,features_hyperparameter_calculation_abnormalCO2)\n",
    "\n",
    "\n",
    "# Result\n",
    "#Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "# {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 80, 'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b84334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Data set\n",
    "\n",
    "# Set features\n",
    "target_hyperparameter_calculation_abnormalCO2 = 'abnormal_Co2_leakage' # Can be any kind of data type\n",
    "features_hyperparameter_calculation_abnormalCO2 = ['IsFloodingPeriode','PM25', 'PM10', 'Temperature', 'Humidity', 'Pressure', 'Precipitation','mine_water_level', 'ground_water_level','RhineWaterLevel','Stream_water_level','Discharge'] # Has to be an array\n",
    "\n",
    "# Call hyperparameter model\n",
    "\n",
    "total_dataset = pd.read_csv('/Users/jan-philippviefhues/Desktop/UNI/Maastricht/um/Thesis/data/datasets/cleaned_datasets/total_dataset_with_precipitation_and_dummies_hourly.csv')\n",
    "calculate_hyperparameters(total_dataset, target_hyperparameter_calculation_abnormalCO2,features_hyperparameter_calculation_abnormalCO2)\n",
    "\n",
    "\n",
    "# Result\n",
    "#Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
    "# {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 80, 'bootstrap': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98528074-7805-44aa-b8a1-4139617990e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the defined hyperparameters and calculate the accuracy\n",
    "\n",
    "print(f'Train Accuracy - : {rf_random.score(X_train, y_train):.3f}')\n",
    "print(f'Train Accuracy - : {rf_random.score(X_test, y_test):.3f}')\n",
    "\n",
    "# The accuracy rates on both sets are euqal enough. We dont have overfitting issue here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
